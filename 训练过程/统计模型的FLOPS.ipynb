{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " # 使用 `torchtnt` 统计模型的FLOPS\n",
    "\n",
    "\n",
    " 本示例展示如何使用 ``torchtnt`` 库估算模型前向传播和反向传播过程中 每秒浮点运算次数（FLOPS）。FLOPS是衡量模型计算复杂度的核心指标，反映模型的算力需求。\n",
    "\n",
    "\n",
    " 本教程演示如何分析神经算子（Neural Operator）模型的计算开销，FLOPS统计的核心价值在于：\n",
    "\n",
    " - 对比不同模型架构的计算效率\n",
    "\n",
    " - 定位模型中的计算瓶颈模块\n",
    "\n",
    " - 优化模型的推理/训练效率\n",
    "\n",
    " - 为模型部署（如选择硬件）提供决策依据\n",
    "\n",
    "\n",
    "\n",
    " 我们将通过FLOPS计算来分析FNO（Fourier Neural Operator）模型的计算资源消耗。\n",
    "\n",
    "\n",
    "\n",
    " ## 导入依赖库\n",
    "\n",
    " 导入FLOPS统计和模型创建所需的核心模块\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtnt\\utils\\version.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "W0207 15:51:00.556000 14828 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试打开的路径是: c:\\Users\\MR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "尝试打开的路径是: c:\\Users\\MR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "# 导入深拷贝工具，用于复制FLOPS统计结果（避免引用传递）\n",
    "from copy import deepcopy\n",
    "# 导入PyTorch核心库\n",
    "import torch\n",
    "# 导入torchtnt中用于统计FLOPS的核心类：基于Tensor Dispatch Mode的FLOPS计数器\n",
    "from torchtnt.utils.flops import FlopTensorDispatchMode\n",
    "\n",
    "# 从neuralop库导入FNO模型（傅里叶神经算子，常用于偏微分方程求解等科学计算场景）\n",
    "from neuralop.models import FNO\n",
    "\n",
    "# 设置计算设备为CPU（也可改为\"cuda\"使用GPU，需确保有可用GPU）\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 创建用于分析的FNO模型\n",
    "\n",
    " 构建一个中等规模的FNO模型，用于演示FLOPS统计流程\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化FNO模型\n",
    "fno = FNO(\n",
    "    n_modes=(64, 64),          # 傅里叶模态数，决定频域特征提取的维度\n",
    "    in_channels=1,             # 输入通道数（示例中为单通道）\n",
    "    out_channels=1,            # 输出通道数（示例中为单通道）\n",
    "    hidden_channels=64,        # 隐藏层通道数，控制模型宽度\n",
    "    projection_channel_ratio=1,# 投影通道比例，用于调整特征投影的维度\n",
    ")\n",
    "\n",
    "# 创建用于FLOPS统计的示例输入张量（模拟真实输入）\n",
    "batch_size = 4                # 批量大小\n",
    "# 生成形状为 [batch_size, in_channels, 128, 128] 的随机输入张量\n",
    "model_input = torch.randn(batch_size, 1, 128, 128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " ## 统计前向传播和反向传播的FLOPS\n",
    "\n",
    " 使用FlopTensorDispatchMode上下文管理器，自动统计模型前向/反向传播的FLOPS\n",
    "\n",
    " （DispatchMode是PyTorch 2.0+的特性，可拦截张量操作并统计计算量）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动FLOPS统计上下文管理器，传入要分析的模型\n",
    "with FlopTensorDispatchMode(fno) as ftdm:\n",
    "    # 执行模型前向传播，并对输出取均值（为反向传播提供标量损失）\n",
    "    res = fno(model_input).mean()\n",
    "    # 深拷贝前向传播的FLOPS统计结果（避免后续reset覆盖）\n",
    "    fno_forward_flops = deepcopy(ftdm.flop_counts)\n",
    "\n",
    "    # 重置FLOPS计数器（清空前向传播的统计结果）\n",
    "    ftdm.reset()\n",
    "    # 执行反向传播（基于前向的均值结果计算梯度）\n",
    "    res.backward()\n",
    "    # 深拷贝反向传播的FLOPS统计结果\n",
    "    fno_backward_flops = deepcopy(ftdm.flop_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 分析FLOPS的详细分布\n",
    "\n",
    " 统计结果以defaultdict嵌套字典的形式存储，键为模型子模块名称，值为对应模块的FLOPS\n",
    "\n",
    " 这种结构可以清晰看到模型各部分的计算开销，定位计算瓶颈。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass FLOPS breakdown:\n",
      "defaultdict(<function FlopTensorDispatchMode.__init__.<locals>.<lambda> at 0x000001C873246DE0>, {'': defaultdict(<class 'int'>, {'convolution.default': 2982150144, 'bmm.default': 138412032}), 'lifting': defaultdict(<class 'int'>, {'convolution.default': 562036736}), 'lifting.fcs.0': defaultdict(<class 'int'>, {'convolution.default': 25165824}), 'lifting.fcs.1': defaultdict(<class 'int'>, {'convolution.default': 536870912}), 'fno_blocks': defaultdict(<class 'int'>, {'convolution.default': 2147483648, 'bmm.default': 138412032}), 'fno_blocks.fno_skips.0': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.fno_skips.0.conv': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.convs.0': defaultdict(<class 'int'>, {'bmm.default': 34603008}), 'fno_blocks.channel_mlp.0': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.channel_mlp.0.fcs.0': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.channel_mlp.0.fcs.1': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.fno_skips.1': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.fno_skips.1.conv': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.convs.1': defaultdict(<class 'int'>, {'bmm.default': 34603008}), 'fno_blocks.channel_mlp.1': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.channel_mlp.1.fcs.0': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.channel_mlp.1.fcs.1': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.fno_skips.2': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.fno_skips.2.conv': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.convs.2': defaultdict(<class 'int'>, {'bmm.default': 34603008}), 'fno_blocks.channel_mlp.2': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.channel_mlp.2.fcs.0': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.channel_mlp.2.fcs.1': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.fno_skips.3': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.fno_skips.3.conv': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.convs.3': defaultdict(<class 'int'>, {'bmm.default': 34603008}), 'fno_blocks.channel_mlp.3': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'fno_blocks.channel_mlp.3.fcs.0': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'fno_blocks.channel_mlp.3.fcs.1': defaultdict(<class 'int'>, {'convolution.default': 134217728}), 'projection': defaultdict(<class 'int'>, {'convolution.default': 272629760}), 'projection.fcs.0': defaultdict(<class 'int'>, {'convolution.default': 268435456}), 'projection.fcs.1': defaultdict(<class 'int'>, {'convolution.default': 4194304})})\n"
     ]
    }
   ],
   "source": [
    "# 打印前向传播的FLOPS分布（按模型子模块拆分）\n",
    "print(\"Forward pass FLOPS breakdown:\")\n",
    "print(fno_forward_flops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## 查找FLOPS消耗最大的模块\n",
    "\n",
    " 为了找到前向传播中FLOPS消耗最大的模块，我们编写一个递归函数\n",
    "\n",
    " 遍历嵌套的defaultdict结构（因为模型子模块是层级嵌套的）：\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO前向传播的最大单模块FLOPS消耗: 2982150144\n",
      "FNO反向传播的最大单模块FLOPS消耗: 5939134464\n"
     ]
    }
   ],
   "source": [
    "# 导入defaultdict（用于处理嵌套的统计结果）\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# 递归查找嵌套字典中最大的FLOPS值\n",
    "# 参数说明：\n",
    "#   flop_count_dict: 嵌套的FLOPS统计字典（键：模块名，值：FLOPS数或子模块字典）\n",
    "#   max_value: 当前递归层级的最大FLOPS值（初始为0）\n",
    "# 返回值：\n",
    "#   整个嵌套字典中的最大FLOPS数值\n",
    "def get_max_flops(flop_count_dict, max_value=0):\n",
    "    # 遍历字典中的每个键值对（模块名：FLOPS/子模块字典）\n",
    "    for _, value in flop_count_dict.items():\n",
    "        # 如果当前值是整数（叶子节点，直接表示该模块的FLOPS）\n",
    "        if isinstance(value, int):\n",
    "            # 更新当前最大FLOPS值\n",
    "            max_value = max(max_value, value)\n",
    "\n",
    "        # 如果当前值是defaultdict（非叶子节点，包含子模块）\n",
    "        elif isinstance(value, defaultdict):\n",
    "            # 递归遍历子模块字典，获取子层级的最大FLOPS\n",
    "            new_val = get_max_flops(value, max_value)\n",
    "            # 更新全局最大FLOPS值\n",
    "            max_value = max(max_value, new_val)\n",
    "    # 返回当前层级及所有子层级的最大FLOPS\n",
    "    return max_value\n",
    "\n",
    "\n",
    "# 打印前向传播中单个模块的最大FLOPS消耗\n",
    "print(f\"FNO前向传播的最大单模块FLOPS消耗: {get_max_flops(fno_forward_flops)}\")\n",
    "# 打印反向传播中单个模块的最大FLOPS消耗\n",
    "print(f\"FNO反向传播的最大单模块FLOPS消耗: {get_max_flops(fno_backward_flops)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
